{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1ab983aa236b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import os\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from midiutil import MIDIFile\n",
    "\n",
    "cuda = torch.device('cuda:0')\n",
    "cuda='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_types = {}\n",
    "\n",
    "chord_map = {np.NaN: 'major',\n",
    "    \"''\":'major',\n",
    "'[]':'major',\n",
    "'minor-seventh':'minor',\n",
    "'dominant':'major',\n",
    "'major':'major',\n",
    "'minor':'minor',\n",
    "'diminished':'minor',\n",
    "'dominant-ninth':'major',\n",
    "'major-sixth':'major',\n",
    "'suspended-fourth':'major',\n",
    "'major-seventh':'major',\n",
    "'dominant-13th':'major',\n",
    "'augmented':'minor',\n",
    "'6':'minor',\n",
    "'7':'major',\n",
    "'maj':'major',\n",
    "'min':'minor',\n",
    "'half-diminished':'minor',\n",
    "'diminished-seventh':'minor',\n",
    "'major-ninth':'major',\n",
    "'major-minor':'major',\n",
    "'minor-ninth':'minor',\n",
    "'minor-sixth':'minor',\n",
    "'suspended-second':'major',\n",
    "'minor-11th':'minor',\n",
    "'dominant-11th':'major',\n",
    "'augmented-seventh':'minor',\n",
    "'min7':'minor',\n",
    "'maj7':'major',\n",
    "' dim7':'minor',\n",
    "'nan':'major',\n",
    "'dominant-seventh':'major',\n",
    "'maj9':'major',\n",
    "'dim':'minor',\n",
    "'minor-major':'minor',\n",
    "'power':'major',\n",
    "'9':'major',\n",
    "'minor-13th':'minor',\n",
    "'augmented-ninth':'minor',\n",
    "'maj69':'major',\n",
    "'m7b5':'minor',\n",
    "'aug':'minor',\n",
    "'dim7':'minor',\n",
    "'minMaj7':'minor',\n",
    "'sus47':'major',\n",
    "'pedal':'major',\n",
    "'min9':\"minor\"}\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-331348dc4a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mchord_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mchord_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_chord_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchord_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-331348dc4a0a>\u001b[0m in \u001b[0;36mget_chord_types\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_chord_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"measure\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"chord_type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mchord_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"chord_type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchord_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"chord_type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "def get_chord_types():\n",
    "    for df in dataframes:\n",
    "        for row in range(len(df[\"measure\"])):\n",
    "            if df[\"chord_type\"][row] != '':\n",
    "                chord_types[df[\"chord_type\"][row]] = chord_types.get(df[\"chord_type\"][row],0) + 1\n",
    "    return chord_types\n",
    "\n",
    "chord_types = get_chord_types()\n",
    "for key in chord_types:\n",
    "    print(\"'\"+str(key)+\"'\")\n",
    "\n",
    "notes = {\"C\":0,\"D\":2,\"E\":4,\"F\":5,\"G\":7,\"A\":9,\"B\":11}\n",
    "note_map = {}\n",
    "for note in notes:\n",
    "    note_map[note+\"0\"] = notes[note]\n",
    "    note_map[note+\"b\"] = (notes[note] - 1)%12\n",
    "    note_map[note+\"#\"] = (notes[note] + 1)%12\n",
    "    note_map[note+\"2\"] = (notes[note] + 1)%12 #weird but whatever\n",
    "    note_map[note+\"-2\"] = (notes[note] + 1)%12 #weird but whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    for row_index in range(len(df[\"measure\"])):\n",
    "        num_measures = int(df[\"measure\"][len(df[\"measure\"])-1])\n",
    "        current_measure = 1\n",
    "        #row_index = 0\n",
    "        this_measures_pitches = np.zeros(12)\n",
    "        this_measures_chord = np.zeros(24)\n",
    "        #let's just get all the data for all the measures. Then we'll go back and turn it into little 4-measure chunks\n",
    "        melody_data = np.zeros((num_measures,12))\n",
    "        chord_data = np.zeros((num_measures))\n",
    "        bad_start = False\n",
    "        if(df[\"chord_root\"][0]) not in note_map:\n",
    "            bad_start = True\n",
    "\n",
    "        for row_index in range(len(df[\"measure\"])):\n",
    "            key_modifier = df[\"key_fifths\"][row_index]*7\n",
    "            if(df[\"chord_root\"][row_index]) not in note_map:\n",
    "                #print(\"bad row\")\n",
    "                assert current_measure == 1, \"bad chord in measure \" + str(current_measure) \n",
    "                continue\n",
    "            if df[\"measure\"][row_index] != current_measure or row_index == 0:\n",
    "                #print(\"df['measure'][row_index] \",df[\"measure\"][row_index])\n",
    "                current_measure_str = df[\"measure\"][row_index]\n",
    "                if current_measure_str == \"X1\":\n",
    "                    current_measure_str = \"8\" #weird case\n",
    "                current_measure = int(current_measure_str) \n",
    "                chord_root_num = (note_map[df[\"chord_root\"][row_index]] + key_modifier)%12\n",
    "                chord_major = 0 if chord_map[df[\"chord_type\"][row_index]] == \"major\" else 1 \n",
    "                chord_num = 12*chord_major + chord_root_num\n",
    "                chord_data[current_measure-1] = chord_num\n",
    "            time_sig_mod = int(df[\"time\"][row_index].split(\"/\")[1]) / int(df[\"time\"][row_index].split(\"/\")[0])\n",
    "            note_name = df[\"note_root\"][row_index]\n",
    "            if note_name != 'rest':\n",
    "                note_dur = int(df[\"note_duration\"][row_index])\n",
    "                note_num = (note_map[note_name] + key_modifier)% 12\n",
    "                melody_data[current_measure-1,note_num] += note_dur * time_sig_mod\n",
    "    return melody_data, chord_data, bad_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2d22d152ed53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mChordDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m#time x batch x features but we don't worry about batch rn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, base_path):\n",
    "        #time x batch x features but we don't worry about batch rn\n",
    "        self.base_path = base_path\n",
    "        self.training_paths = os.listdir(base_path)\n",
    "        dataframes = []\n",
    "        for path in self.training_paths:\n",
    "            full_path = base_path + \"/\" + path\n",
    "            dataframes.append(pd.read_csv(full_path))\n",
    "            \n",
    "        self.dataframes = dataframes\n",
    "        self.measures_per_phrase = 4\n",
    "        self.hop_size = 1\n",
    "        self.note_map = note_map\n",
    "        self.songs = []\n",
    "        #self.song_lengths = []\n",
    "        for df_num, df in enumerate(self.dataframes):\n",
    "#             for row_index in range(len(df[\"measure\"])):\n",
    "#                 print(df[\"chord_root\"][row_index])\n",
    "            print(\"df_num: \", df_num)\n",
    "            num_measures = int(df[\"measure\"][len(df[\"measure\"])-1])\n",
    "            current_measure = 1\n",
    "            #row_index = 0\n",
    "            this_measures_pitches = np.zeros(12)\n",
    "            this_measures_chord = np.zeros(24)\n",
    "            #let's just get all the data for all the measures. Then we'll go back and turn it into little 4-measure chunks\n",
    "            melody_data = np.zeros((num_measures,12))\n",
    "            chord_data = np.zeros((num_measures))\n",
    "            bad_start = False\n",
    "            if(df[\"chord_root\"][0]) not in self.note_map:\n",
    "                bad_start = True\n",
    "            \n",
    "            for row_index in range(len(df[\"measure\"])):\n",
    "                key_modifier = df[\"key_fifths\"][row_index]*7\n",
    "                if(df[\"chord_root\"][row_index]) not in self.note_map:\n",
    "                    #print(\"bad row\")\n",
    "                    assert current_measure == 1, \"bad chord in measure \" + str(current_measure) \n",
    "                    continue\n",
    "                if df[\"measure\"][row_index] != current_measure or row_index == 0:\n",
    "                    #print(\"df['measure'][row_index] \",df[\"measure\"][row_index])\n",
    "                    current_measure_str = df[\"measure\"][row_index]\n",
    "                    if current_measure_str == \"X1\":\n",
    "                        current_measure_str = \"8\" #weird case\n",
    "                    current_measure = int(current_measure_str) \n",
    "                    chord_root_num = (self.note_map[df[\"chord_root\"][row_index]] + key_modifier)%12\n",
    "                    chord_major = 0 if chord_map[df[\"chord_type\"][row_index]] == \"major\" else 1 \n",
    "                    chord_num = 12*chord_major + chord_root_num\n",
    "                    chord_data[current_measure-1] = chord_num\n",
    "                time_sig_mod = int(df[\"time\"][row_index].split(\"/\")[1]) / int(df[\"time\"][row_index].split(\"/\")[0])\n",
    "                note_name = df[\"note_root\"][row_index]\n",
    "                if note_name != 'rest':\n",
    "                    note_dur = int(df[\"note_duration\"][row_index])\n",
    "                    note_num = (self.note_map[note_name] + key_modifier)% 12\n",
    "                    melody_data[current_measure-1,note_num] += note_dur * time_sig_mod\n",
    "            if bad_start:\n",
    "                self.songs.append((melody_data[1:], chord_data[1:]))\n",
    "            else:\n",
    "                self.songs.append((melody_data, chord_data))\n",
    "            #self.song_lengths.append(num_measures)\n",
    "        \n",
    "        self.phrases = []\n",
    "        for song_num in range(len(self.songs)):\n",
    "            base_measure_num = 1\n",
    "            num_measures = len(self.songs[song_num][0])\n",
    "            while base_measure_num + self.measures_per_phrase <= num_measures: #still collecting datas\n",
    "                melody_data_to_append = self.songs[song_num][0][base_measure_num-1:base_measure_num-1+self.measures_per_phrase]\n",
    "                chord_data_to_append = self.songs[song_num][1][base_measure_num-1:base_measure_num-1+self.measures_per_phrase]\n",
    "                self.phrases.append((torch.tensor(melody_data_to_append,dtype=torch.float32), torch.tensor(chord_data_to_append,dtype=torch.long)))\n",
    "                base_measure_num += self.hop_size\n",
    "         \n",
    "    def __len__(self):\n",
    "        return len(self.phrases)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.phrases[idx]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChordDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c8b554865133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainDataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChordDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv_train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtestDatasetAll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChordDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv_test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChordDataset' is not defined"
     ]
    }
   ],
   "source": [
    "trainDataset = ChordDataset(\"csv_train\")\n",
    "\n",
    "testDatasetAll = ChordDataset(\"csv_test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = int(len(testDatasetAll)*0.8)\n",
    "testset, valset = random_split(testDatasetAll, [num_test, len(testDatasetAll)-num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: make it bidirectional girl \n",
    "class ChordLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_size):\n",
    "        super(ChordLSTM,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = torch.nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, dropout=0.2, batch_first=True, bidirectional=True).to(cuda)\n",
    "        self.fc = torch.nn.Linear(self.hidden_size*2, 24).to(cuda)\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        #note: we don't want to reset hidden each time when we test this - want to feed data one at a time (faster)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(2*self.num_layers, self.batch_size, self.hidden_size).to(cuda), torch.zeros(2*self.num_layers, self.batch_size, self.hidden_size).to(cuda))\n",
    "        \n",
    "    def forward(self, input_sequence_batch):\n",
    "        self.hidden = self.init_hidden()\n",
    "        #print(\"input batch size \", input_sequence_batch.size())\n",
    "        #print(\"hidden size \", self.hidden[0].size())\n",
    "        lstm_out, self.hidden = self.lstm(input_sequence_batch, self.hidden)\n",
    "        X = self.fc(lstm_out)\n",
    "        X = self.tanh(X)\n",
    "        return X #do sigmoid later \n",
    "    \n",
    "    def loss(self, predictions, labels):\n",
    "        #print(\"predictions size \", predictions.size())\n",
    "        #print(\"labels size \", labels.size())\n",
    "        pred = torch.transpose(predictions, 1, 2)\n",
    "        return self.loss_func(pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:  tensor(2.5576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.3623, device='cuda:0')\n",
      "train_loss:  tensor(2.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2767, device='cuda:0')\n",
      "train_loss:  tensor(2.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2498, device='cuda:0')\n",
      "train_loss:  tensor(2.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2401, device='cuda:0')\n",
      "train_loss:  tensor(2.1864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2298, device='cuda:0')\n",
      "train_loss:  tensor(2.1714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2244, device='cuda:0')\n",
      "train_loss:  tensor(2.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2236, device='cuda:0')\n",
      "train_loss:  tensor(2.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2129, device='cuda:0')\n",
      "train_loss:  tensor(2.1369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2197, device='cuda:0')\n",
      "num_times_val_loss_decreased  1\n",
      "train_loss:  tensor(2.1273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2198, device='cuda:0')\n",
      "num_times_val_loss_decreased  2\n",
      "train_loss:  tensor(2.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2129, device='cuda:0')\n",
      "num_times_val_loss_decreased  3\n",
      "train_loss:  tensor(2.1093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2121, device='cuda:0')\n",
      "train_loss:  tensor(2.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2161, device='cuda:0')\n",
      "num_times_val_loss_decreased  1\n",
      "train_loss:  tensor(2.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2134, device='cuda:0')\n",
      "num_times_val_loss_decreased  2\n",
      "train_loss:  tensor(2.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2111, device='cuda:0')\n",
      "train_loss:  tensor(2.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2177, device='cuda:0')\n",
      "num_times_val_loss_decreased  1\n",
      "train_loss:  tensor(2.0702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2172, device='cuda:0')\n",
      "num_times_val_loss_decreased  2\n",
      "train_loss:  tensor(2.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2123, device='cuda:0')\n",
      "num_times_val_loss_decreased  3\n",
      "train_loss:  tensor(2.0565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2138, device='cuda:0')\n",
      "num_times_val_loss_decreased  4\n",
      "train_loss:  tensor(2.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2132, device='cuda:0')\n",
      "num_times_val_loss_decreased  5\n",
      "train_loss:  tensor(2.0435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2211, device='cuda:0')\n",
      "num_times_val_loss_decreased  6\n",
      "train_loss:  tensor(2.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2260, device='cuda:0')\n",
      "num_times_val_loss_decreased  7\n",
      "train_loss:  tensor(2.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2193, device='cuda:0')\n",
      "num_times_val_loss_decreased  8\n",
      "train_loss:  tensor(2.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2214, device='cuda:0')\n",
      "num_times_val_loss_decreased  9\n",
      "train_loss:  tensor(2.0188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2203, device='cuda:0')\n",
      "num_times_val_loss_decreased  10\n",
      "train_loss:  tensor(2.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2285, device='cuda:0')\n",
      "num_times_val_loss_decreased  11\n",
      "train_loss:  tensor(2.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2235, device='cuda:0')\n",
      "num_times_val_loss_decreased  12\n",
      "train_loss:  tensor(2.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2232, device='cuda:0')\n",
      "num_times_val_loss_decreased  13\n",
      "train_loss:  tensor(1.9963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2291, device='cuda:0')\n",
      "num_times_val_loss_decreased  14\n",
      "train_loss:  tensor(1.9918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2267, device='cuda:0')\n",
      "num_times_val_loss_decreased  15\n",
      "train_loss:  tensor(1.9863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2284, device='cuda:0')\n",
      "num_times_val_loss_decreased  16\n",
      "train_loss:  tensor(1.9812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2253, device='cuda:0')\n",
      "num_times_val_loss_decreased  17\n",
      "train_loss:  tensor(1.9768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2282, device='cuda:0')\n",
      "num_times_val_loss_decreased  18\n",
      "train_loss:  tensor(1.9711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2300, device='cuda:0')\n",
      "num_times_val_loss_decreased  19\n",
      "train_loss:  tensor(1.9674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2271, device='cuda:0')\n",
      "num_times_val_loss_decreased  20\n",
      "train_loss:  tensor(1.9630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "val_loss:  tensor(2.2392, device='cuda:0')\n",
      "num_times_val_loss_decreased  21\n",
      "EARLY STOPPING\n"
     ]
    }
   ],
   "source": [
    "def train(num_epochs):\n",
    "    batch_size = 512\n",
    "    train_loader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last = True)\n",
    "    val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "    model = ChordLSTM(12, 128, 2, batch_size)\n",
    "    model.to(cuda)\n",
    "    learning_rate = .0005\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    num_epochs = 300\n",
    "    num_times_val_loss_decreased = 0\n",
    "    prev_val_loss = np.inf\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_sum = 0\n",
    "        val_loss_sum = 0\n",
    "        train_count = 0\n",
    "        val_count = 0\n",
    "        #for (x_padded,y_padded,x_lens,y_lens) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        for (x,y) in train_loader:\n",
    "            #print(\"shape of x \", x.size())\n",
    "            model.zero_grad()\n",
    "            output = model(x.to(cuda))\n",
    "            loss = model.loss(output.to(cuda),y.to(cuda))\n",
    "            train_loss_sum += loss\n",
    "            loss.backward() #this might die... \n",
    "            optimizer.step()\n",
    "            train_count += 1\n",
    "        print(\"train_loss: \", train_loss_sum/train_count)\n",
    "        \n",
    "        #validate\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for (x,y) in val_loader:\n",
    "                model.zero_grad()\n",
    "                output = model(x.to(cuda))\n",
    "                loss = model.loss(output.to(cuda),y.to(cuda))\n",
    "                val_loss_sum += loss\n",
    "                val_count += 1\n",
    "            print(\"val_loss: \", val_loss_sum/val_count)\n",
    "            if val_loss_sum/val_count > prev_val_loss:\n",
    "                num_times_val_loss_decreased += 1\n",
    "                print(\"num_times_val_loss_decreased \", num_times_val_loss_decreased)\n",
    "            else:\n",
    "                torch.save({\"epoch\":epoch, \"model_state_dict\":model.state_dict(),\"optimizer_state_dict\":optimizer.state_dict(),\"loss\":val_loss_sum/val_count}, \"checkpoints/checkpoint.pth.tar\")\n",
    "                prev_val_loss = val_loss_sum/val_count\n",
    "                num_times_val_loss_decreased = 0 #for 10 times in a row failing \n",
    "            if num_times_val_loss_decreased > 20:\n",
    "                print(\"EARLY STOPPING\")\n",
    "                break\n",
    "\n",
    "\n",
    "train(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChordLSTM(\n",
       "  (lstm): LSTM(12, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=24, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (loss_func): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChordLSTM(12, 128, 2, 1)\n",
    "model.load_state_dict(torch.load(\"checkpoints/checkpoint.pth.tar\")[\"model_state_dict\"])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_maxes  torch.return_types.max(\n",
      "values=tensor([[0.2028, 0.2265, 0.2366, 0.2226]], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([[ 5, 10, 10, 10]], device='cuda:0'))\n",
      "tensor([[[0.0274, 0.0274, 0.0275, 0.0537, 0.0274, 0.2028, 0.0274, 0.0274,\n",
      "          0.0275, 0.0274, 0.0484, 0.0274, 0.1457, 0.0274, 0.0278, 0.0275,\n",
      "          0.0274, 0.0275, 0.0274, 0.0275, 0.0274, 0.0275, 0.0274, 0.0274],\n",
      "         [0.0307, 0.0307, 0.0307, 0.0522, 0.0307, 0.0336, 0.0307, 0.0307,\n",
      "          0.0307, 0.0307, 0.2265, 0.0307, 0.0318, 0.0307, 0.0308, 0.0309,\n",
      "          0.0307, 0.0307, 0.0307, 0.0730, 0.0307, 0.0307, 0.0307, 0.0307],\n",
      "         [0.0320, 0.0320, 0.0320, 0.0459, 0.0320, 0.0336, 0.0320, 0.0320,\n",
      "          0.0320, 0.0320, 0.2366, 0.0320, 0.0334, 0.0320, 0.0323, 0.0322,\n",
      "          0.0320, 0.0320, 0.0320, 0.0416, 0.0320, 0.0320, 0.0320, 0.0320],\n",
      "         [0.0302, 0.0301, 0.0302, 0.0522, 0.0301, 0.0310, 0.0301, 0.0302,\n",
      "          0.0301, 0.0301, 0.2226, 0.0301, 0.0303, 0.0301, 0.0354, 0.0301,\n",
      "          0.0301, 0.0301, 0.0301, 0.0859, 0.0301, 0.0301, 0.0301, 0.0301]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([ 5, 10,  3, 10])\n"
     ]
    }
   ],
   "source": [
    "mel, targets = testset[50]\n",
    "inp = torch.zeros((1,4,12)).to(cuda)\n",
    "inp[0,:,:] = mel\n",
    "sm = torch.nn.Softmax(dim=2)\n",
    "output_guess = sm(model(inp))\n",
    "output_maxes = torch.max(output_guess,axis=2)\n",
    "print(\"output_maxes \", output_maxes)\n",
    "print(output_guess)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 16.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.6667,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 16.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.6667,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 16.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 10.6667,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, 16.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, 10.6667,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 16.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.6667,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 16.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.6667,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  4.0000,  0.0000,  0.0000,  0.0000,  4.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  2.6667,  0.0000, 10.6667,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 10.6667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          5.3333,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 12.0000,  0.0000,  1.3333,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  5.3333,  0.0000,  0.0000,  0.0000,\n",
      "          5.3333,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,  8.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         16.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.6667,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  4.0000,  0.0000, 12.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          5.3333,  0.0000,  0.0000,  5.3333],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,  2.6667,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  4.0000,  0.0000,  0.0000,  4.0000,  0.0000,  8.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          2.6667,  0.0000,  0.0000,  5.3333],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000, 10.6667,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,\n",
      "          8.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  8.0000],\n",
      "        [ 0.0000,  0.0000,  8.0000,  0.0000,  8.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  8.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 10.6667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          8.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  5.3333,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  8.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,  0.0000,\n",
      "          8.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  8.0000],\n",
      "        [ 0.0000,  4.0000,  0.0000,  0.0000,  0.0000,  4.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  2.6667,  0.0000, 10.6667,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 10.6667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          5.3333,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 12.0000,  0.0000,  1.3333,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  5.3333,  0.0000,  0.0000,  0.0000,\n",
      "          5.3333,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,  8.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         16.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.6667,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  4.0000,  0.0000, 12.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          5.3333,  0.0000,  0.0000,  5.3333],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,  2.6667,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  4.0000,  0.0000,  0.0000,  4.0000,  0.0000,  8.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          2.6667,  0.0000,  0.0000,  5.3333],\n",
      "        [ 0.0000,  5.3333,  0.0000,  0.0000, 10.6667,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.0000,  0.0000,\n",
      "          8.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  8.0000],\n",
      "        [ 0.0000,  0.0000,  8.0000,  0.0000,  8.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0',\n",
      "       dtype=torch.float64) tensor([ 1.,  1.,  1.,  1.,  9.,  9.,  8.,  8.,  1.,  1., 10., 10.,  9.,  8.,\n",
      "         1.,  8.,  1.,  8.,  9.,  8., 18.,  3.,  2.,  2.,  7.,  8.,  9., 10.,\n",
      "        15.,  8.,  1.,  1.,  1.,  1.,  6.,  6.,  2.,  2.,  6.,  6., 15., 15.,\n",
      "         2., 23.,  2., 23.,  7.,  3.,  5.,  9.,  1.,  8.,  9.,  8., 18.,  3.,\n",
      "         2.,  2.,  7.,  8.,  9., 10., 15.,  8.,  1.,  1.,  1.,  1.],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "output:  [tensor([[ 6,  6,  1, 10]], device='cuda:0'), tensor([[ 4, 13, 11, 11]], device='cuda:0'), tensor([[ 6,  6,  1, 10]], device='cuda:0'), tensor([[0, 0, 0, 0]], device='cuda:0'), tensor([[1, 6, 1, 6]], device='cuda:0'), tensor([[13,  9,  4, 11]], device='cuda:0'), tensor([[ 9,  9,  4, 13]], device='cuda:0'), tensor([[ 9, 13,  9, 11]], device='cuda:0'), tensor([[4, 4, 9, 9]], device='cuda:0'), tensor([[9, 6, 6, 6]], device='cuda:0'), tensor([[1, 6, 6, 6]], device='cuda:0'), tensor([[13, 13,  9,  6]], device='cuda:0'), tensor([[1, 1, 1, 6]], device='cuda:0'), tensor([[13, 13, 13,  9]], device='cuda:0'), tensor([[4, 4, 9, 6]], device='cuda:0'), tensor([[ 4, 13,  9, 13]], device='cuda:0')]\n",
      "guess:  [ 6.  6.  1. 10.  4. 13. 11. 11.  6.  6.  1. 10.  0.  0.  0.  0.  1.  6.\n",
      "  1.  6. 13.  9.  4. 11.  9.  9.  4. 13.  9. 13.  9. 11.  4.  4.  9.  9.\n",
      "  9.  6.  6.  6.  1.  6.  6.  6. 13. 13.  9.  6.  1.  1.  1.  6. 13. 13.\n",
      " 13.  9.  4.  4.  9.  6.  4. 13.  9. 13.]\n",
      "gt:  [ 1.  1.  1.  1.  9.  9.  8.  8.  1.  1. 10. 10.  9.  8.  1.  8.  1.  8.\n",
      "  9.  8. 18.  3.  2.  2.  7.  8.  9. 10. 15.  8.  1.  1.  1.  1.  6.  6.\n",
      "  2.  2.  6.  6. 15. 15.  2. 23.  2. 23.  7.  3.  5.  9.  1.  8.  9.  8.\n",
      " 18.  3.  2.  2.  7.  8.  9. 10. 15.  8.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "test_songs_listed = os.listdir(\"csv_test\")\n",
    "df_to_test = pd.read_csv(\"csv_test/\" + test_songs_listed[50])\n",
    "df_to_test_melody, df_to_test_chords, bad_start = process_dataframe(df_to_test)\n",
    "if bad_start:\n",
    "    df_to_test_melody = df_to_test_melody[1:]\n",
    "    df_to_test_chords = df_to_test_chords[1:]\n",
    "df_to_test_melody = torch.tensor(df_to_test_melody).to(cuda)\n",
    "df_to_test_chords = torch.tensor(df_to_test_chords).to(cuda)\n",
    "print(df_to_test_melody, df_to_test_chords)\n",
    "\n",
    "base_measure_num = 1\n",
    "measures_per_phrase = 4\n",
    "hop_size = 4\n",
    "num_measures = len(df_to_test_melody)\n",
    "output = []\n",
    "while base_measure_num + measures_per_phrase <= num_measures: #run lstm every 4 measures\n",
    "    melody_tensor = torch.zeros((1,4,12),dtype=torch.float32).to(cuda)\n",
    "    melody_tensor[0,:,:] += df_to_test_melody[base_measure_num-1:base_measure_num-1+measures_per_phrase]\n",
    "    #chord_data_to_append = self.songs[song_num][1][base_measure_num-1:base_measure_num-1+self.measures_per_phrase]\n",
    "    model_out = model(melody_tensor)\n",
    "    output.append(torch.max(model_out,axis=2)[1])\n",
    "    base_measure_num += hop_size\n",
    "print(\"output: \", output)\n",
    "final_output = np.zeros(len(output)*4)\n",
    "for i,o in enumerate(output):\n",
    "    final_output[i*4:i*4+4] = o.cpu()\n",
    "print(\"guess: \", final_output)\n",
    "print(\"gt: \", np.array(df_to_test_chords.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bachelors III.csv\n",
      "3/4\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.6666666666666665\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.6666666666666665\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.6666666666666665\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.4444444444433333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.4444444444433333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  4.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.6666666666666665\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.6666666666666665\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.6666666666666665\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.4444444444433333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.4444444444433333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  4.0\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  0.6666666666666666\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  1.3333333333333333\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "mod  0.3333333333333333\n",
      "beat_duration  2.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  10.0\n",
      "note:  58.0\n",
      "note:  62.0\n",
      "note:  65.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  11.0\n",
      "note:  59.0\n",
      "note:  63.0\n",
      "note:  66.0\n",
      "CHORD:  11.0\n",
      "note:  59.0\n",
      "note:  63.0\n",
      "note:  66.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  10.0\n",
      "note:  58.0\n",
      "note:  62.0\n",
      "note:  65.0\n",
      "CHORD:  0.0\n",
      "note:  48.0\n",
      "note:  52.0\n",
      "note:  55.0\n",
      "CHORD:  0.0\n",
      "note:  48.0\n",
      "note:  52.0\n",
      "note:  55.0\n",
      "CHORD:  0.0\n",
      "note:  48.0\n",
      "note:  52.0\n",
      "note:  55.0\n",
      "CHORD:  0.0\n",
      "note:  48.0\n",
      "note:  52.0\n",
      "note:  55.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  11.0\n",
      "note:  59.0\n",
      "note:  63.0\n",
      "note:  66.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  11.0\n",
      "note:  59.0\n",
      "note:  63.0\n",
      "note:  66.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  1.0\n",
      "note:  49.0\n",
      "note:  53.0\n",
      "note:  56.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  6.0\n",
      "note:  54.0\n",
      "note:  58.0\n",
      "note:  61.0\n",
      "CHORD:  4.0\n",
      "note:  52.0\n",
      "note:  56.0\n",
      "note:  59.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n",
      "CHORD:  9.0\n",
      "note:  57.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "CHORD:  13.0\n",
      "note:  61.0\n",
      "note:  64.0\n",
      "note:  68.0\n"
     ]
    }
   ],
   "source": [
    "print(test_songs_listed[50])\n",
    "\n",
    "chord_template_minor = np.array([0,3,7])\n",
    "chord_template_major = np.array([0,4,7])\n",
    "def write_midi(df, chords):\n",
    "    MyMIDI = MIDIFile(2)\n",
    "    MyMIDI.addTempo(0, 0, 100)\n",
    "    MyMIDI.addTempo(1, 0, 100)\n",
    "    current_location = 0\n",
    "    num_time_sig = int(df[\"time\"][0].split(\"/\")[0])\n",
    "    denom_time_sig = int(df[\"time\"][1].split(\"/\")[0])\n",
    "    MyMIDI.addTimeSignature(0,0,num_time_sig,2,24)\n",
    "    MyMIDI.addTimeSignature(1,0,num_time_sig,2,24)\n",
    "    print(df[\"time\"][0])\n",
    "    for ri, row in enumerate(df[\"measure\"]):\n",
    "        row_index = ri\n",
    "        time_sig_mod = int(df[\"time\"][row_index].split(\"/\")[1]) / int(df[\"time\"][row_index].split(\"/\")[0]) \n",
    "        time_sig_mod = 1/(denom_time_sig)\n",
    "        print(\"mod \", time_sig_mod)\n",
    "        beat_duration = float(df[\"note_duration\"][row_index])*time_sig_mod\n",
    "        if df[\"note_root\"][row_index] == \"rest\":\n",
    "            current_location += beat_duration\n",
    "            continue\n",
    "        midi_num = (note_map[df[\"note_root\"][row_index]] + int(df[\"key_fifths\"][row_index])*7)%12 + 12*int(df[\"note_octave\"][row_index])\n",
    "        print(\"beat_duration \", beat_duration)\n",
    "        MyMIDI.addNote(0,0,midi_num,current_location,beat_duration,100)\n",
    "        current_location += beat_duration\n",
    "    \n",
    "    current_location = 0\n",
    "    for chord in chords:\n",
    "        print(\"CHORD: \", chord)\n",
    "        if chord < 12:\n",
    "            notes = chord_template_major + chord + 48\n",
    "        else:\n",
    "            notes = chord_template_minor + chord + 48\n",
    "        for note in notes:\n",
    "            print(\"note: \", note)\n",
    "            MyMIDI.addNote(1,0,int(note),current_location,num_time_sig,100)\n",
    "        current_location += num_time_sig\n",
    "    with open(\"bach.mid\", \"wb\") as output_file:\n",
    "        MyMIDI.writeFile(output_file)\n",
    "                              \n",
    "write_midi(df_to_test, final_output)                         \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "#df_to_test\n",
    "# track    = 0\n",
    "# channel  = 0\n",
    "# time     = 0    # In beats\n",
    "# tempo    = 60   # In BPM\n",
    "# volume   = 100  # 0-127, as per the MIDI standard\n",
    "\n",
    "# MyMIDI = MIDIFile(1)  # One track, defaults to format 1 (tempo track is created\n",
    "#                       # automatically)\n",
    "# MyMIDI.addTempo(track, time, tempo)\n",
    "\n",
    "# for i, pitch in enumerate(degrees):\n",
    "#     MyMIDI.addNote(track, channel, pitch, time + i, duration, volume)\n",
    "\n",
    "# with open(\"major-scale.mid\", \"wb\") as output_file:\n",
    "#     MyMIDI.writeFile(output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
